#!/usr/bin/env python2

import argparse
import calendar
import datetime as dt
from datetime import datetime
import icalendar
from operator import itemgetter
import os, os.path
from os.path import join
import cPickle
import pytz
import re
import sys
import threading
import time
import tzlocal
import urllib


# settings
ical_age_limit = 3600 * 12;


# global
tz = tzlocal.get_localzone()


# functions

def exit(error_msg):
    sys.exit(os.path.basename(__file__) + ": Error: " + error_msg)


def __hash(string):
    return str(hash(string) & 0xffffffff)


def read_local_cal(local_file):
  cal = icalendar.Calendar()

  if os.path.exists(local_file):
      with open(local_file) as f:
          local_lines = f.readlines()

      i = 0
      while i < len(local_lines):
          cur = local_lines[i].rstrip()
          i += 1

          if not cur:
              continue

          # parse for "date start_time-end_time"
          rdate = re.sub(" .*", "", cur)
          rstart = re.sub(".* ([0-9]*:[0-9]*)-[0-9]*:[0-9]*", "\g<1>", cur)
          rend = re.sub(".*-", "", cur)

          # next line must exist and contain event name
          cur = local_lines[i].rstrip()
          i += 1

          name = cur
          location = ""
          description = ""

          # next line can exist and contain location
          if i < len(local_lines):
              cur = local_lines[i].rstrip()

              if cur:
                  i += 1
                  location = cur

          # next line can exist and contain description
          if i < len(local_lines):
              cur = local_lines[i].rstrip()

              if cur:
                  i += 1
                  description = cur

          # create event

          dtstart = datetime.strptime(rdate + " " + rstart, '%d.%m.%y %H:%M')
          dtend = datetime.strptime(rdate + " " + rend, '%d.%m.%y %H:%M')

          dtstart = tz.localize(dtstart)
          dtend = tz.localize(dtend)

          event = icalendar.Event()
          event.add('dtstart', dtstart)
          event.add('dtend', dtend)
          event.add('summary', name)
          event.add('location', location)
          event.add('description', description)

          cal.add_component(event)

  return cal

def events_date(cals, event_date, filters, location=False, description=False):
  global tz

  print event_date.strftime("%A, %x:")

  events = []

  for cal in cals:
    for component in cal.walk("VEVENT"):
      dtstart = component.get('dtstart').dt

      if dtstart.date() == event_date:

        if dtstart.tzinfo is None:
            dt_local = tz.localize(dtstart)
        else:
            dt_local = dtstart.astimezone(tz) # localize time
        start = dt_local.time()

        # filter
        skip = False
        summary = component.get('summary')
        for f in filters:
          if re.search(f, summary):
            skip = True
            break

        if not skip:
          events.append( (start, component) )

  events.sort(key=itemgetter(0))

  for event in events:
    start = event[0]
    component = event[1]
    dtend = component.get('dtend').dt

    if dtend.tzinfo is None:
        dt_local = tz.localize(dtend)
    else:
        dt_local = dtend.astimezone(tz) # localize time
    end = dt_local.time()

    summary = component.get('summary')

    loc_str = ''
    if location:
      loc = component.get('location')
      loc_str = '\n                 %s' % loc

    desc_str = ''
    if description:
      desc = component.get('description')
      desc_str = '\n                 %s' % desc

    p = '  %s - %s: %s%s%s' % (start.strftime('%H:%M'), end.strftime('%H:%M'),\
                               summary, desc_str, loc_str)
    print p.encode('utf-8')


  return ''


def thread_read_cache(cur_file, out):
  with open(cur_file, 'rb') as f:
    cal = cPickle.load(f)

  out.append(cal)


def thread_write_cache(cur_file, cal):
  with open(cur_file, 'wb') as f:
    cPickle.dump(cal, f)


if __name__ == '__main__':

    # setup file names

    home = os.path.expanduser("~")
    confdir = join(home, '.sia')
    cachedir = join(confdir, 'cache')

    url_file = join(confdir, 'urls')
    filter_file = join(confdir, 'filters')
    local_file = join(confdir, 'local')
    local_cache = join(cachedir, 'local.pkl')

    # parse arguments

    parser = argparse.ArgumentParser(description='A remote ical aggregator.')
    parser.add_argument('-s', dest='day', action='store_true', default=False, help='Display single day (default).')
    parser.add_argument('-w', dest='week', action='store_true', default=False, help='Display week.')
    parser.add_argument('-m', dest='month', action='store_true', default=False, help='Display month.')
    parser.add_argument('-q', dest='quiet', action='store_true', default=False, help='Don\'t show any output. Useful in combination with -r.')
    parser.add_argument('-o', dest='offset', metavar='n', type=int, action='store', default=0, help='Numerical offset from today, this week, or this month.')
    parser.add_argument('-d', dest='description', action='store_true', default=False, help='Display event description.')
    parser.add_argument('-l', dest='location', action='store_true', default=False, help='Display event location.')
    parser.add_argument('-r', dest='force_retrieve', action='store_true', default=False, help='Force retrieving remote icals.')
    parser.add_argument('-n', dest='no_retrieve', action='store_true', default=False, help='Don\'t allow retrieving remote icals, abort if no cache file is present. This overrides -r.')

    args = parser.parse_args()


    # check for argument conflicts

    if sum([ args.day, args.week, args.month ]) > 1:
      err =  "Error: conflicting flags (",
      if args.day:
        err += "-d",
      if args.week:
        err += "-w",
      if args.month:
        err += "-m",
      err += "). Aborting."

      exit(err)


    # check for config directory

    if not os.path.exists(confdir):
      os.makedirs(confdir)

    if not os.path.exists(cachedir):
      os.makedirs(cachedir)

# load config files

    if not os.path.exists(url_file):
      exit('url file not found (should be at ~/.sia/urls).')
    else:
      with open(url_file) as f:
        urls = f.readlines()

    if not os.path.exists(filter_file):
      filters = []
    else:
      with open(filter_file) as f:
        filters = f.readlines()

      for i, elem in enumerate(filters):
        filters[i] = elem.rstrip('\n')


    # calendar loading
    # one pickle for each local and remote cal

    cals = []


    # local cal

    if (not os.path.exists(local_cache) or
        os.path.getmtime(local_file) > os.path.getmtime(local_cache)):

      local_cal = read_local_cal(local_file)

      with open(local_cache, 'wb') as f:
        cPickle.dump(local_cal, f)
    else:
      with open(local_cache, 'rb') as f:
        local_cal = cPickle.load(f)

    if os.path.exists(local_file):
        with open(local_file) as f:
            local_lines = f.readlines()

    cals.append(local_cal)


    # remote cals

    printed = False
    read_threads = []
    write_threads = []

    for url in urls:
      url = url.rstrip()
      cur_file = join(cachedir, __hash(url) + '.pkl')

      if (not args.no_retrieve and
          (args.force_retrieve or
           not os.path.exists(cur_file) or
           time.time() - os.path.getmtime(cur_file) > ical_age_limit)):

        # fetching remote cals and saving them each in their own cache file,
        #   name is generate as hash from url

        if not printed:
          print "Retrieving icals..."
          printed = True
        
        # TODO catch errors
        u = urllib.urlopen(url)
        buf = u.read()
        cal = icalendar.Calendar.from_ical(buf)

        # write pickle in thread
        thread = threading.Thread(target=thread_write_cache, args=(cur_file, cal))
        write_threads.append(thread)
        thread.start()
        #with open(cur_file, 'wb') as f:
        #  cPickle.dump(cal, f)

        cals.append(cal)

      elif not os.path.exists(cur_file):
        exit("Missing a cache file, aborting.")

      else:
        # read pickle from file

        result = []

        thread = threading.Thread(target=thread_read_cache, args=(cur_file, result))
        read_threads.append([ thread, result ])
        thread.start()


    # process threads

    if len(read_threads) != 0:
      for t in read_threads:
        t[0].join()
        cals.append(t[1][0])


    # quiet option

    if args.quiet:
      sys.exit()


    # display

    target = dt.date.today()

    if args.month:

      if args.offset != 0:
        target = target + dt.timedelta(days=args.offset*365/12)

      first_offset = -1 * (target.day - 1)
      target = target + dt.timedelta(days=first_offset)
      cur = target

      last = calendar.monthrange(target.year, target.month)[1]
      for day in range(0, last):
        cur = target + dt.timedelta(days=day)
        print events_date(cals, cur, filters, location=args.location, description=args.description)

    elif args.week:

      if args.offset != 0:
        target = target + dt.timedelta(weeks=args.offset)

      monday_offset = -1 * target.weekday()
      target = target + dt.timedelta(days=monday_offset)
      cur = target

      for day in range(0, 7):
        cur = target + dt.timedelta(days=day)
        print events_date(cals, cur, filters, location=args.location, description=args.description)

    else:
      if args.offset != 0:
        target = dt.date.today() + dt.timedelta(days=args.offset)

      print events_date(cals, target, filters, location=args.location, description=args.description)


    # wait for write_threads

    if len(write_threads) != 0:
      for t in write_threads:
        t.join()
